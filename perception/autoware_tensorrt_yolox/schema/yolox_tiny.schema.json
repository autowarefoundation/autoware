{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Parameters for tensorrt_yolox_tiny Nodes",
  "type": "object",
  "definitions": {
    "yolox_tiny": {
      "type": "object",
      "properties": {
        "model_path": {
          "type": "string",
          "default": "$(var data_path)/tensorrt_yolox/$(var model_name).onnx",
          "description": "Path to onnx model."
        },
        "label_path": {
          "type": "string",
          "default": "$(var data_path)/tensorrt_yolox/label.txt",
          "description": "Path to label file."
        },
        "score_threshold": {
          "type": "number",
          "default": 0.35,
          "minimum": 0.0,
          "maximum": 1.0,
          "description": "A threshold value of existence probability score, all of objects with score less than this threshold are ignored."
        },
        "nms_threshold": {
          "type": "number",
          "default": 0.7,
          "minimum": 0.0,
          "maximum": 1.0,
          "description": "A threshold value of NMS."
        },
        "precision": {
          "type": "string",
          "default": "fp16",
          "description": "Operation precision to be used on inference. Valid value is one of: [fp32, fp16, int8]."
        },
        "calibration_algorithm": {
          "type": "string",
          "default": "MinMax",
          "description": "Calibration algorithm to be used for quantization when precision==int8. Valid value is one of: [Entropy, (Legacy | Percentile), MinMax]."
        },
        "dla_core_id": {
          "type": "number",
          "default": -1,
          "description": "If positive ID value is specified, the node assign inference task to the DLA core."
        },
        "quantize_first_layer": {
          "type": "boolean",
          "default": false,
          "description": "If true, set the operating precision for the first (input) layer to be fp16. This option is valid only when precision==int8."
        },
        "quantize_last_layer": {
          "type": "boolean",
          "default": false,
          "description": "If true, set the operating precision for the last (output) layer to be fp16. This option is valid only when precision==int8."
        },
        "profile_per_layer": {
          "type": "boolean",
          "default": false,
          "description": "If true, profiler function will be enabled. Since the profile function may affect execution speed, it is recommended to set this flag true only for development purpose."
        },
        "clip_value": {
          "type": "number",
          "default": 0.0,
          "description": "If positive value is specified, the value of each layer output will be clipped between [0.0, clip_value]. This option is valid only when precision==int8 and used to manually specify the dynamic range instead of using any calibration."
        },
        "preprocess_on_gpu": {
          "type": "boolean",
          "default": true,
          "description": "If true, pre-processing is performed on GPU."
        },
        "gpu_id": {
          "type": "integer",
          "default": 0,
          "description": "GPU ID for selecting CUDA device"
        },
        "calibration_image_list_path": {
          "type": "string",
          "default": "",
          "description": "Path to a file which contains path to images. Those images will be used for int8 quantization."
        }
      },
      "required": [
        "model_path",
        "label_path",
        "score_threshold",
        "nms_threshold",
        "precision",
        "calibration_algorithm",
        "dla_core_id",
        "quantize_first_layer",
        "quantize_last_layer",
        "profile_per_layer",
        "clip_value",
        "preprocess_on_gpu",
        "gpu_id"
      ]
    }
  },
  "properties": {
    "/**": {
      "type": "object",
      "properties": {
        "ros__parameters": {
          "$ref": "#/definitions/yolox_tiny"
        }
      },
      "required": ["ros__parameters"]
    }
  },
  "required": ["/**"]
}
