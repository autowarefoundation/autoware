/**:
  ros__parameters:
    model_path: "$(var data_path)/tensorrt_yolox/$(var model_name).onnx"
    label_path: "$(var data_path)/tensorrt_yolox/label.txt"
    score_threshold: 0.35
    nms_threshold: 0.7
    precision: "int8" # Operation precision to be used on inference. Valid value is one of: [fp32, fp16, int8].
    calibration_algorithm: "Entropy" # Calibration algorithm to be used for quantization when precision==int8. Valid value is one of: [Entropy, (Legacy | Percentile), MinMax].
    dla_core_id: -1 # If positive ID value is specified, the node assign inference task to the DLA core.
    quantize_first_layer: false # If true, set the operating precision for the first (input) layer to be fp16. This option is valid only when precision==int8.
    quantize_last_layer: false # If true, set the operating precision for the last (output) layer to be fp16. This option is valid only when precision==int8.
    profile_per_layer: false # If true, profiler function will be enabled. Since the profile function may affect execution speed, it is recommended to set this flag true only for development purpose.
    clip_value: 6.0 # If positive value is specified, the value of each layer output will be clipped between [0.0, clip_value]. This option is valid only when precision==int8 and used to manually specify the dynamic range instead of using any calibration.
    preprocess_on_gpu: true # If true, pre-processing is performed on GPU.
    calibration_image_list_path: "" # Path to a file which contains path to images. Those images will be used for int8 quantization.
